## This script performs sentiment analysis using a pre-trained Transformer model
## from the Hugging Face library. It processes data in batches for efficiency.

import pandas as pd
import torch
from transformers import pipeline
import matplotlib.pyplot as plt
from tqdm import tqdm

def analyze_sentiment_transformer_batch(texts: list[str], sentiment_pipeline, batch_size: int = 16) -> list[dict]:
    """
    Analyzes a list of texts in batches for efficient processing.

    Args:
        texts (list[str]): A list of strings to analyze.
        sentiment_pipeline: The pre-loaded Hugging Face pipeline object.
        batch_size (int): The number of texts to process at once.

    Returns:
        A list of dictionaries, where each dictionary contains the 'label' and 'score'.
    """
    results = []
    # Use tqdm to create a progress bar for the loop
    for i in tqdm(range(0, len(texts), batch_size), desc="Processing Batches"):
        batch = texts[i:i + batch_size]
        # The pipeline automatically handles tokenization and inference for the batch.
        # We add `truncation=True` to handle texts longer than the model's max sequence length.
        batch_results = sentiment_pipeline(batch, truncation=True)
        results.extend(batch_results)
    return results

def standardize_label(label: str) -> str:
    """Standardizes the model's output label to a common format."""
    if label == 'POS':
        return 'Positive'
    elif label == 'NEG':
        return 'Negative'
    # The model 'finiteautomata/bertweet-base-sentiment-analysis' uses 'NEU' for neutral
    elif label == 'NEU':
        return 'Neutral'
    return 'Unknown'


if __name__ == '__main__':
    # --- 1. Setup ---
    # Check if a GPU is available and set the device accordingly
    # Using a GPU will be significantly faster.
    device = 0 if torch.cuda.is_available() else -1 # 0 for first GPU, -1 for CPU
    if device == 0:
        print("[*] GPU detected. Running on CUDA device 0.")
    else:
        print("[*] No GPU detected. Running on CPU (this may be slow).")

    # --- Configuration for input and output files ---
    INPUT_FILE = 'processed_corpus.csv'
    OUTPUT_FILE = 'transformer_sentiment_results.csv'
    CHART_FILE = 'transformer_sentiment_distribution.png'

    # --- 2. Load Data and Initialize Model ---
    print(f"\n--- Starting Transformer sentiment analysis for {INPUT_FILE} ---")
    try:
        # Load the corpus file generated by your preprocessing script
        corpus_df = pd.read_csv(INPUT_FILE)
        # Ensure the text column is clean and of string type, fill NaNs with empty strings
        corpus_df['cleaned_text'] = corpus_df['cleaned_text'].astype(str).fillna('')
        print(f"Loaded {len(corpus_df)} total entries from the corpus.")

        # Initialize the Hugging Face pipeline once
        # This will download the model (a few hundred MB) on the first run.
        print("\n[*] Initializing Hugging Face sentiment analysis pipeline...")
        model_name = "finiteautomata/bertweet-base-sentiment-analysis"
        sentiment_pipeline = pipeline(
            "sentiment-analysis",
            model=model_name,
            device=device # Tell the pipeline to use the GPU if available
        )
        print("[*] Pipeline initialized successfully.")

        # --- 3. Run Analysis in Batches ---
        # Convert the DataFrame column to a list for batch processing
        texts_to_analyze = corpus_df['cleaned_text'].tolist()
        
        # Get the raw results from the model
        raw_results = analyze_sentiment_transformer_batch(texts_to_analyze, sentiment_pipeline)

        # --- 4. Process and Save Results ---
        # Extract the labels and scores from the results
        labels = [standardize_label(res['label']) for res in raw_results]
        scores = [res['score'] for res in raw_results]

        # Add the results as new columns to the DataFrame
        corpus_df['transformer_label'] = labels
        corpus_df['transformer_score'] = scores

        # Save the updated DataFrame to a new CSV file
        corpus_df.to_csv(OUTPUT_FILE, index=False)
        print(f"\nSuccessfully saved Transformer sentiment analysis results to '{OUTPUT_FILE}'")

        # --- 5. Display Summary ---
        print("\n--- Overall Sentiment Distribution (Transformer) ---")
        print(corpus_df['transformer_label'].value_counts(normalize=True).mul(100).round(2).astype(str) + '%')

        print("\n--- Example Results ---")
        print(corpus_df[['cleaned_text', 'transformer_label', 'transformer_score']].head(10))

        # --- 6. Visualize the Sentiment Distribution ---
        print("\n" + "="*80 + "\n--- Generating sentiment distribution plot ---")
        plt.style.use('ggplot')
        sentiment_counts = corpus_df['transformer_label'].value_counts().reindex(['Positive', 'Neutral', 'Negative'], fill_value=0)
        ax = sentiment_counts.plot(kind='bar', color=['#4CAF50', '#FFC107', '#F44336'], figsize=(10, 6), edgecolor='black')
        ax.bar_label(ax.containers[0], fmt='%d', label_type='edge', padding=3)
        plt.title('Transformer Sentiment Distribution of Reddit Corpus', fontsize=16, fontweight='bold')
        plt.xlabel('Sentiment Category', fontsize=12)
        plt.ylabel('Number of Comments', fontsize=12)
        plt.xticks(rotation=0, fontsize=10)
        plt.tight_layout()
        plt.savefig(CHART_FILE)
        print(f"Sentiment distribution plot saved to '{CHART_FILE}'")
        plt.show()

    except FileNotFoundError:
        print(f"\nError: Input file not found at '{INPUT_FILE}'.")
        print("Please ensure 'preprocessing.py' has been run to generate the corpus file.")
    except Exception as e:
        print(f"\nAn unexpected error occurred: {e}")
