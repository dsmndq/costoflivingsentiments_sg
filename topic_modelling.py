"""
This script performs Topic Modeling on the comments identified as 'Negative'
by the sentiment analysis phase. It uses Latent Dirichlet Allocation (LDA)
to discover the key themes driving negative sentiment and visualizes the
distribution of these topics in a pie chart.
"""
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.decomposition import LatentDirichletAllocation

def display_topics(model, feature_names, num_top_words):
    """
    Displays the top words for each topic generated by the LDA model.
    """
    print("\n" + "="*60)
    print("           Discovered Topics in Negative Comments")
    print("="*60)
    topic_dict = {}
    for topic_idx, topic in enumerate(model.components_):
        # Get the indices of the top words for this topic
        top_word_indices = topic.argsort()[:-num_top_words - 1:-1]
        # Get the actual words from the feature names (vocabulary)
        top_words = [feature_names[i] for i in top_word_indices]
        topic_dict[topic_idx] = top_words
        print(f"Topic #{topic_idx + 1}: {', '.join(top_words)}")
    print("="*60)
    return topic_dict

def plot_topic_distribution(document_topics, topic_keywords):
    """
    Creates and saves a pie chart showing the distribution of documents across topics,
    with a legend that lists the top keywords for each topic.
    """
    print("\n[*] Generating topic distribution pie chart...")
    topic_counts = pd.Series(document_topics).value_counts().sort_index()
    
    # Create the labels for the legend, including the top keywords
    legend_labels = []
    for i in topic_counts.index:
        keywords_str = ", ".join(topic_keywords[i][:5]) # Get top 5 keywords
        legend_labels.append(f"Topic {i + 1}: {keywords_str}...")

    # Create the pie chart
    plt.style.use('ggplot')
    fig, ax = plt.subplots(figsize=(14, 9))
    
    # Explode the largest slice for emphasis
    explode = [0] * len(topic_counts)
    if not topic_counts.empty:
        explode[np.argmax(topic_counts.values)] = 0.1

    wedges, texts, autotexts = ax.pie(
        topic_counts, 
        autopct='%1.1f%%', 
        startangle=140, 
        explode=explode,
        pctdistance=0.85,
        colors=plt.cm.Paired.colors # Use a nice color map
    )

    # Improve aesthetics
    ax.legend(wedges, legend_labels,
              title="Discovered Topics (Top 5 Keywords)",
              loc="center left",
              bbox_to_anchor=(1, 0, 0.5, 1),
              fontsize=12)
    
    plt.setp(autotexts, size=10, weight="bold", color="white")
    ax.set_title("Distribution of Negative Sentiment Topics", fontsize=16, fontweight='bold')
    
    # Ensure the pie chart is a circle
    ax.axis('equal')
    
    # Save the figure
    chart_filename = 'negative_topics_distribution.png'
    plt.savefig(chart_filename, bbox_inches='tight')
    print(f"[*] Pie chart saved to '{chart_filename}'")
    plt.show()


if __name__ == '__main__':
    # --- Configuration ---
    INPUT_FILE = 'transformer_sentiment_results.csv'
    NUM_TOPICS = 7
    NUM_TOP_WORDS = 15

    # --- 1. Load and Filter Data ---
    print(f"--- Starting Topic Modeling on Negative Sentiment from {INPUT_FILE} ---")
    try:
        df = pd.read_csv(INPUT_FILE)
        negative_df = df[df['transformer_label'] == 'Negative'].copy()
        print(f"Isolated {len(negative_df)} negative comments for topic modeling.")

        if len(negative_df) < NUM_TOPICS:
            print("[!] Error: Not enough negative comments to perform topic modeling. Exiting.")
            exit()
            
        negative_corpus = negative_df['cleaned_text'].astype(str).tolist()

        # --- 2. Feature Engineering for LDA (Vectorization) ---
        print("\n[*] Vectorizing the negative corpus...")
        vectorizer = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')
        X = vectorizer.fit_transform(negative_corpus)
        print("[*] Vectorization complete.")

        # --- 3. Train the LDA Model ---
        print(f"[*] Training LDA model to find {NUM_TOPICS} topics...")
        lda = LatentDirichletAllocation(n_components=NUM_TOPICS, random_state=42)
        lda.fit(X)
        print("[*] LDA model training complete.")

        # --- 4. Display and Interpret the Results ---
        feature_names = vectorizer.get_feature_names_out()
        topic_keywords = display_topics(lda, feature_names, NUM_TOP_WORDS)
        
        # --- 5. Assign Topics and Visualize ---
        # Assign each comment to its most likely topic
        doc_topic_dist = lda.transform(X)
        document_topics = doc_topic_dist.argmax(axis=1)
        
        # Generate and save the pie chart with the discovered topic keywords
        plot_topic_distribution(document_topics, topic_keywords)

    except FileNotFoundError:
        print(f"\nError: Input file not found at '{INPUT_FILE}'.")
        print("Please run 'sentiment_analysis_transformer.py' first.")
    except Exception as e:
        print(f"\nAn unexpected error occurred: {e}")

